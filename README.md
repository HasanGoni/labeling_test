# labeling_test


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

``` python
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload

This repo code mostly taken from
[here](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/PerSAM/Personalize_SAM_with_one_shot_using_Hugging_Face.ipynb)

## Install

``` sh
git clone git@github.com:HasanGoni/labeling_test.git
cd labelling_test
pip install -e .
```

``` python
## Special considertation regarding `Huggingface`
```

> When `transformers` model is downloaded, it normally downloaded in
> local `~/.cache` folder. In case you have space scarcity in ~/.cache,
> you should change the download folder. Can be done in different way.
> One way could be following.

``` python
import os
os.environ['HF_HOME'] = '/home/ai_test/data/huggingface'
```

here I am changing the download folder to
/home/ai_test/data/huggingface\`. Make sure the repository exist

# Importing libraries

``` python
from huggingface_hub import hf_hub_download
from PIL import Image
import cv2
import matplotlib.pyplot as plt
from fastcore.all import *
import torch
import torch.nn.functional as F
from torchvision.transforms.functional import resize, to_pil_image
import numpy as  np
from pathlib import Path
from typing import Tuple, List, Union
from transformers import AutoProcessor, SamModel
```

## How to use

## Get data

> One consideration regarding `reading image and mask`. Right now you
> should use `PIL` for reading image and `opencv` for reading mask. I
> will try to correct it. But right now one shoudl use this way

``` python
# Downloading from Niels_rogge hugging face repo
# image file
file_name = hf_hub_download(repo_id="nielsr/persam-dog", filename="dog.jpg", repo_type="dataset")
# image mask file
m_file_name = hf_hub_download(repo_id="nielsr/persam-dog", filename="dog_mask.png", repo_type="dataset")
tst_im_path = hf_hub_download(
    repo_id="nielsr/persam-dog", 
    filename="new_dog.jpg", 
    repo_type="dataset")

ref_image = Image.open(file_name).convert('RGB')
ref_mask = cv2.imread(m_file_name)
ref_mask = cv2.cvtColor(ref_mask, cv2.COLOR_BGR2RGB)
tst_img = Image.open(tst_im_path).convert('RGB')
ref_image
```

![](index_files/figure-commonmark/cell-5-output-1.png)

``` python
tst_img
```

![](index_files/figure-commonmark/cell-6-output-1.png)

### getting model

``` python
processor = AutoProcessor.from_pretrained("facebook/sam-vit-huge")
# model = PerSamModel.from_pretrained("facebook/sam-vit-huge")
model = SamModel.from_pretrained("facebook/sam-vit-huge")
```

### getting first prediciton mask

``` python
#device='cuda' # in case `gpu` is available otherwise use `cpu`
device='cpu'
```

``` python
outputs, tst_feat,topk_xy, topk_label, input_sam, best_idx = get_first_prediction(
                                        ref_img=ref_image,
                                        ref_msk=ref_mask,
                                        tst_img=tst_img,
                                        model=model,
                                        processor=processor, 
                                        device=device,
                                        print_=False)
```

``` python
show_(outputs['pred_masks'].to('cpu').numpy()[0][0][0])
```

![](index_files/figure-commonmark/cell-10-output-1.png)

``` python
outputs_fr,_, _, _,masks_fr = get_first_refined_mask(
    ref_image=ref_image,
    ref_mask=ref_mask,
    tst_img=tst_img,
    processor=processor,
    model=model,
    print_=False,
    device=device,
     )
```

``` python
show_all_masks(masks_fr, outputs=outputs_fr)
```

![](index_files/figure-commonmark/cell-12-output-1.png)

- So we have got 3 masks from first prediction.
- For the next step you should tell which one should be used as a prompt
  input for next prediction.
  - Normally best `IoU` should give you the best mask, in case it
    doesnâ€™t provide that, then you should manually decide which mask you
    want to use.
  - this can be done in next function `get_last_refined_masks`, where
    parameter `best_idx` will control which idx one should use as a
    prompt.
  - best_idx = 0 means first mask
  - best_idx = None means from above mask use the best `IoU`.
- In the above case you can see best `IoU = 0.99` is providing me the
  best mask. Therefore for next prompt I will be using best_idx=None for
  next input prompt

``` python
output_f, masks_f = get_last_refined_masks(
    ref_image=ref_image,
    ref_mask=ref_mask,
    processor=processor,
    model=model,
    tst_img=tst_img,
    device=device,
    print_=False,
    outputs=outputs_fr,
    masks=masks_fr,
    best_idx=None
)
```

``` python
show_all_masks(masks_f, outputs=output_f)
```

![](index_files/figure-commonmark/cell-14-output-1.png)

> So we have our final masks. we can save the last image. Normally if
> you use previously best mask idx then actually here `99.99%`, you
> should get the best mask with best `IoU`

- in case it is not, then again in save_mask function,index=\[0,1 or 2\]

``` python
path = Path(Path.home(), 'Schreibtisch/projects/data/persam')
```

``` python
save_mask(
    masks_f,
    path=Path(path,'mask_test.png'),
    outputs=output_f,
    index=None
)
```
