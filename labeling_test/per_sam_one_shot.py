# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_per_sam.ipynb.

# %% auto 0
__all__ = ['processor', 'model', 'get_preprocess_shape', 'normalize_and_padding', 'get_ref_mask', 'get_target_feat', 'get_norm_',
           'get_cosine_sim']

# %% ../nbs/01_per_sam.ipynb 2
from pathlib import Path
from fastcore.all import *
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import torch
from torchvision.transforms.functional import resize, to_pil_image
from typing import Tuple
import torch.nn.functional as F

# %% ../nbs/01_per_sam.ipynb 4
from transformers import AutoProcessor, SamModel
# from transformers import PerSamModel

processor = AutoProcessor.from_pretrained("facebook/sam-vit-huge")
# model = PerSamModel.from_pretrained("facebook/sam-vit-huge")
model = SamModel.from_pretrained("facebook/sam-vit-huge")
     

# %% ../nbs/01_per_sam.ipynb 28
def get_preprocess_shape(
    oldh:int,
    oldw:int,
    long_side_length:int
    ):
    ' Scaling output size based on long_side_lenght'

    scale = long_side_length * 1 / max(oldh, oldw)
    newh, neww = int((scale * oldh) + 0.5), int((scale* oldw) + 0.5)
    return (newh, neww)

# %% ../nbs/01_per_sam.ipynb 46
def normalize_and_padding(
    x:torch.Tensor, #expected shape (b, c, h, w)
    pixel_mean=[123.675, 116.28, 103.55], # imagenet data mean * 255
    pixel_std=[58.395, 57.12, 57.375], # imagenet std * 255
    im_size:int=1024, # desired image size
    )->torch.Tensor:
    'Normalize with imagenet data and pad if necessary'

    pixel_mean_ = torch.Tensor(pixel_mean).view(-1,1,1)
    pixel_std_ = torch.Tensor(pixel_std).view(-1,1,1)

    x = (x - pixel_mean_) / pixel_std_

    h, w = x.shape[-2:]
    padh = im_size - h
    padw = im_size - w
    # TODO
    # need to check height and width right or not
    return F.pad(x, (0, padh, 0 , padw))





# %% ../nbs/01_per_sam.ipynb 71
def get_ref_mask(
    ref_mask:np.ndarray,
    ref_feat:torch.Tensor # ref feature from model
    ):
    ' get reference mask '

    ref_msk_ = prepare_mask(ref_mask)
    ref_msk_ = F.interpolate(ref_msk_, size=ref_feat.shape[0: 2], mode="bilinear")
    ref_msk_ = ref_msk_.squeeze()[0]
    return ref_msk_




# %% ../nbs/01_per_sam.ipynb 74
def get_target_feat(
    ref_msk:torch.Tensor,
    ref_feat:torch.Tensor
    ):
    ' extract features from target'

    ref_msk_ = get_ref_mask(ref_msk, ref_feat=ref_feat)
    trgt_feat = ref_feat[ref_msk_ > 0]
    targt_emb = trgt_feat.mean(0).unsqueeze(0)
    ##########################################

    trgt_ft_ = target_emb / target_emb.norm(dim=-1, keepdim=True)
    print(f' trgt emb shape = {targt_emb.shape}')
    trgt_emb = targt_emb.unsqueeze(0)
    return trgt_ft_



# %% ../nbs/01_per_sam.ipynb 80
def get_norm_(x:torch.Tensor):
    ' Calcualte norm of x'
    return  x / x.norm(dim=0, keepdim=True)

# %% ../nbs/01_per_sam.ipynb 81
def get_cosine_sim(
    trgt_feat:torch.Tensor,
    tst_feat:torch.Tensor
    ):
    ' Calculate cosine similarity between tst and target image'

    c, h, w = tst_feat.shape
    tst_feat_norm = get_norm_(tst_feat)
    tst_feat_norm_r = tst_feat_norm.reshape(
        c, 
        h*w
    )
    sim = trgt_feat @ tst_feat_norm_r
    return sim.reshape(1, 1, h, w)

